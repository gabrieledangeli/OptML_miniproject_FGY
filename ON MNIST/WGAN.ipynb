{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dange\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] Impossibile trovare la procedura specificata\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "# Importing needed libraries\n",
    "\n",
    "import torch, os\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import grad\n",
    "from helpers import *\n",
    "from torchmetrics.image.inception import InceptionScore\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from CGDs import ACGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=100, output_dim=1, input_size=32):\n",
    "        super(Generator, self).__init__()\n",
    "        self.input_dim = input_dim \n",
    "        self.output_dim = output_dim \n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 128 * (self.input_size // 4) * (self.input_size // 4)),\n",
    "            nn.BatchNorm1d(128 * (self.input_size // 4) * (self.input_size // 4)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # The following layers are used to upsample the input\n",
    "        # noise and generate an output image.\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, self.output_dim, 4, 2, 1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "        # This function initializes the weights and biases of the \n",
    "        # generator's layers:\n",
    "        initialize_weights(self) \n",
    "\n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        The input to the forward method represents the input noise \n",
    "        to the generator model. It returns the generated output image.\n",
    "        '''\n",
    "        \n",
    "        x = self.fc(input)\n",
    "        x = x.view(-1, 128, (self.input_size // 4), (self.input_size // 4)) # Reshapes x to match the expected size for the subsequent transposed convolutional layers. \n",
    "        x = self.deconv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim=1, output_dim=1, input_size=32):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(self.input_dim, 64, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 * (self.input_size // 4) * (self.input_size // 4), 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, self.output_dim),\n",
    "            # nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "        # This function initializes the weights and biases of the \n",
    "        # discriminator's layers:\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        The input to the forward method represents the input image\n",
    "        It returns the output prediction, which represents the discriminator's assessment of the input image.\n",
    "        '''\n",
    "        x = self.conv(input)\n",
    "        x = x.view(-1, 128 * (self.input_size // 4) * (self.input_size // 4))\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN(object):\n",
    "    def __init__(self, epoch, batch_size, save_dir, result_dir, dataset, device, input_size, lrG, lrD, beta1, beta2):\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.save_dir = save_dir\n",
    "        self.result_dir = result_dir\n",
    "\n",
    "        self.device = device\n",
    "        self.dataset = dataset\n",
    "\n",
    "        self.input_size = input_size    # Default: 32\n",
    "\n",
    "        self.D_losses = []\n",
    "        self.G_losses = []\n",
    "        self.inception_scores = []\n",
    "        self.frechet_inception_distances = []\n",
    "\n",
    "        self.model_name = 'WGAN'        \n",
    "        self.z_dim = 62                 # Represents the dimensionality of the (Gaussian) random input vector used by the generator.\n",
    "        self.d_param_max = 0.01         # Clipping value\n",
    "        self.iteration_g_per_d = 5      # Specifies the number of iterations of the generator per discriminator iteration. \n",
    "                                        # This controls the relative training frequency of the generator and discriminator.\n",
    "\n",
    "        self.inception=InceptionScore(normalize=True)\n",
    "        self.f=FrechetInceptionDistance(feature=64,normalize=True)\n",
    "\n",
    "        # Transformation to be applied on data in the DataLoader function\n",
    "        transform = transforms.Compose([\n",
    "                                        transforms.Resize((input_size, input_size)), \n",
    "                                        transforms.ToTensor(), \n",
    "                                        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "                                        ])\n",
    "        \n",
    "        if self.dataset == 'cifar10':\n",
    "                self.data_loader = DataLoader(\n",
    "                    datasets.CIFAR10('data/cifar10', train=True, download=False, transform=transform),\n",
    "                    batch_size=batch_size, shuffle=True)\n",
    "        elif self.dataset == 'mnist':\n",
    "                self.data_loader = DataLoader(\n",
    "                    datasets.MNIST('data/mnist', train=True, download=False, transform=transform),\n",
    "                    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        data = self.data_loader.__iter__().__next__()[0]\n",
    "\n",
    "        # Initialize generator, discriminator and optimizers\n",
    "        self.G = Generator(input_dim=self.z_dim, output_dim=data.shape[1], input_size=self.input_size)\n",
    "        self.D = Discriminator(input_dim=data.shape[1], output_dim=1, input_size=self.input_size)\n",
    "        self.G_optimizer = optim.Adam(self.G.parameters(), lr=lrG, betas=(beta1, beta2))\n",
    "        self.D_optimizer = optim.Adam(self.D.parameters(), lr=lrD, betas=(beta1, beta2))\n",
    "\n",
    "        if self.device == 'cuda:0':\n",
    "            self.G.cuda()\n",
    "            self.D.cuda()\n",
    "\n",
    "        # Fixed noise: By setting up a fixed noise vector, the WGAN can generate consistent\n",
    "        # samples from the generator over the course of training. This allows for visualizing\n",
    "        # the progression of generated images or comparing them across different training iterations.\n",
    "        self.sample_z = torch.rand((self.batch_size, self.z_dim))\n",
    "        if self.device == 'cuda:0':\n",
    "            self.sample_z = self.sample_z.cuda()\n",
    "\n",
    "        print('---------------INITIALIZATION-----------------')\n",
    "        print('|           Model: WGAN with Adam            |')\n",
    "        print('----------------------------------------------')\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        self.y_real = torch.ones(self.batch_size, 1) # Initialize labels for real samples (i.e. 1)\n",
    "        self.y_fake = torch.zeros(self.batch_size, 1) # Initialize labels for fake samples (i.e. 0)\n",
    "\n",
    "        if self.device == 'cuda:0':\n",
    "            self.y_real = self.y_real.cuda()\n",
    "            self.y_fake = self.y_fake.cuda()\n",
    "\n",
    "        self.D.train() #D network in train mode\n",
    "\n",
    "        print('Start training!')\n",
    "        tot_iter = 0\n",
    "        for epoch in range(self.epoch):\n",
    "            iteration_losses_G = []     # Auxiliary arrays to compute the mean loss for each epoch\n",
    "            iteration_losses_D = []\n",
    "\n",
    "            self.G.train() #G network in train mode\n",
    "\n",
    "            for iter, (x_train, _) in enumerate(self.data_loader):\n",
    "                if iter == (self.data_loader.dataset.__len__() // self.batch_size): # Exit the loop when it has been used the whole dataset\n",
    "                    break\n",
    "\n",
    "                z_noise = torch.rand((self.batch_size, self.z_dim))\n",
    "\n",
    "                if self.device == 'cuda:0':\n",
    "                    x_train = x_train.cuda()\n",
    "                    z_noise = z_noise.cuda()\n",
    "\n",
    "                # PART 1: UPDATE THE DISCRIMINATOR\n",
    "                self.D_optimizer.zero_grad()\n",
    "\n",
    "                D_real = self.D(x_train) # Computes the discriminator output for real data\n",
    "                D_real_loss = -torch.mean(D_real) # Calculates the loss for the discriminator on real data. \n",
    "                                                  # The objective is to maximize the average output of the discriminator for real data.\n",
    "\n",
    "                G_ = self.G(z_noise) # Generates fake data using the generator\n",
    "                D_fake = self.D(G_) # Computes the discriminator output for fake data.\n",
    "                D_fake_loss = torch.mean(D_fake) # Calculates the loss for the discriminator on fake data. \n",
    "                                                 # The objective is to minimize the average output of the discriminator for fake data.\n",
    "\n",
    "                D_loss = D_real_loss + D_fake_loss # Calculates the total discriminator loss as the sum of the losses on real and fake data.\n",
    "\n",
    "                D_loss.backward()\n",
    "                self.D_optimizer.step()\n",
    "\n",
    "                # Clipping D parameters to a specified range to enforce Lipschitz continuity.\n",
    "                for p in self.D.parameters():\n",
    "                    p.data.clamp_(-self.d_param_max, self.d_param_max)\n",
    "\n",
    "                if ((iter+1) % self.iteration_g_per_d) == 0:\n",
    "                    # PART 2: UPDATE THE GENERATOR\n",
    "                    self.G_optimizer.zero_grad()\n",
    "\n",
    "                    G_ = self.G(z_noise)\n",
    "                    D_fake = self.D(G_)\n",
    "                    G_loss = -torch.mean(D_fake) # Calculates the generator loss as the negative average output of the discriminator for fake data. \n",
    "                                                 # The objective is to maximize the average output of the discriminator for the generated fake data.\n",
    "\n",
    "                    iteration_losses_G.append(G_loss.item())\n",
    "\n",
    "                    G_loss.backward()\n",
    "\n",
    "                    self.G_optimizer.step()\n",
    "\n",
    "                    iteration_losses_D.append(D_loss.item())\n",
    "                \n",
    "                if tot_iter % 1000 == 0:        # Compute the Inception scores and the FID scores every 1000 iterations\n",
    "                     with torch.no_grad():\n",
    "                        score=self.IS()\n",
    "                        self.inception_scores.append(score[0].item())\n",
    "                        distance=self.FID()\n",
    "                        self.frechet_inception_distances.append(distance.item())\n",
    "                tot_iter += 1\n",
    "            \n",
    "            self.G_losses.append(np.mean(iteration_losses_G))\n",
    "            self.D_losses.append(np.mean(iteration_losses_D))\n",
    "\n",
    "            print(f'Epoch: {epoch+1}/{self.epoch}')\n",
    "            print(f'Discriminator loss: {self.D_losses[-1]}')\n",
    "            print(f'Generator loss: {self.G_losses[-1]}')\n",
    "\n",
    "            with torch.no_grad():\n",
    "                self.visualize_results((epoch+1))\n",
    "\n",
    "        print(\"Training finished.\")\n",
    "        #self.save()\n",
    "        generate_animation(self.result_dir + '/' + self.dataset + '/' + self.model_name + '/' + self.model_name,\n",
    "                                 self.epoch)\n",
    "        loss_plot(self.G_losses, self.D_losses, os.path.join(self.save_dir, self.dataset, self.model_name), self.model_name)\n",
    "        save_scores(self.inception_scores, self.save_dir, self.dataset, self.model_name, IS=True)\n",
    "        save_scores(self.frechet_inception_distances, self.save_dir, self.dataset, self.model_name, FID=True)\n",
    "        save_loss(self.G_losses, self.save_dir, self.dataset, self.model_name, Generator=True)\n",
    "        save_loss(self.D_losses, self.save_dir, self.dataset, self.model_name, Discriminator=True)\n",
    "    \n",
    "\n",
    "\n",
    "    def IS(self):\n",
    "        self.G.eval()\n",
    "        images = self.G(self.sample_z)\n",
    "        self.inception.update(images.cpu())\n",
    "        IS=self.inception.compute()   \n",
    "        return IS\n",
    "        \n",
    "\n",
    "\n",
    "    def FID(self):\n",
    "        self.G.eval()\n",
    "        imagesG = self.G(self.sample_z)\n",
    "        imagesR=self.data_loader.__iter__().__next__()[0]\n",
    "        self.f.update(imagesR.cpu(), real=True)\n",
    "        self.f.update(imagesG.cpu(), real=False)\n",
    "        FID=self.f.compute()\n",
    "        return FID\n",
    "\n",
    "\n",
    "\n",
    "    def visualize_results(self, epoch):\n",
    "        self.G.eval()\n",
    "\n",
    "        if not os.path.exists(self.result_dir + '/' + self.dataset + '/' + self.model_name):\n",
    "            os.makedirs(self.result_dir + '/' + self.dataset + '/' + self.model_name)\n",
    "\n",
    "        samples = self.G(self.sample_z)\n",
    "        \n",
    "        if self.device == 'cuda:0':\n",
    "            samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n",
    "        else:\n",
    "            samples = samples.data.numpy().transpose(0, 2, 3, 1)\n",
    "\n",
    "        samples = (samples + 1) / 2\n",
    "        save_images(samples, [8, 8],\n",
    "                          self.result_dir + '/' + self.dataset + '/' + self.model_name + '/' + self.model_name + '_epoch%03d' % epoch + '.png')\n",
    "    \n",
    "\n",
    "\n",
    "    def print_networks(self):\n",
    "        print('---------- Networks architecture -------------')\n",
    "        print(self.G)\n",
    "        print(self.D)\n",
    "        print('-----------------------------------------------')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN_GP(object):\n",
    "    def __init__(self, epoch, batch_size, save_dir, result_dir, dataset, device, input_size, lrG, lrD, beta1, beta2):\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.dataset = dataset\n",
    "\n",
    "        self.save_dir = save_dir\n",
    "        self.result_dir = result_dir\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.model_name = 'WGAN_GP'\n",
    "        self.z_dim = 62\n",
    "        self.lambda_ = 10\n",
    "        self.iteration_g_per_d = 5\n",
    "\n",
    "        \n",
    "        self.G_losses = []\n",
    "        self.D_losses = []\n",
    "        self.inception_scores = []\n",
    "        self.frechet_inception_distances = []\n",
    "\n",
    "        self.inception=InceptionScore(normalize=True)\n",
    "        self.f=FrechetInceptionDistance(feature=64,normalize=True)\n",
    "        \n",
    "        # Transformation to be applied on data in the DataLoader function\n",
    "        transform = transforms.Compose([\n",
    "                                transforms.Resize((self.input_size, self.input_size)), \n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "                                ])\n",
    "\n",
    "        if self.dataset == 'cifar10':\n",
    "                self.data_loader = DataLoader(\n",
    "                    datasets.CIFAR10('data/cifar10', train=True, download=False, transform=transform),\n",
    "                    batch_size=batch_size, shuffle=True)\n",
    "        elif self.dataset == 'mnist':\n",
    "                self.data_loader = DataLoader(\n",
    "                    datasets.MNIST('data/mnist', train=True, download=False, transform=transform),\n",
    "                    batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        data = self.data_loader.__iter__().__next__()[0]\n",
    "\n",
    "        # Initialization of optimizers and of generator and discriminator\n",
    "        self.G = Generator(input_dim=self.z_dim, output_dim=data.shape[1], input_size=self.input_size)\n",
    "        self.D = Discriminator(input_dim=data.shape[1], output_dim=1, input_size=self.input_size)\n",
    "        self.G_optimizer = optim.Adam(self.G.parameters(), lr=lrG, betas=(beta1, beta2))\n",
    "        self.D_optimizer = optim.Adam(self.D.parameters(), lr=lrD, betas=(beta1, beta2))\n",
    "\n",
    "        if self.device == 'cuda:0':\n",
    "            self.G.cuda()\n",
    "            self.D.cuda()\n",
    "\n",
    "        # Fixed noise: By setting up a fixed noise vector, the WGAN can generate consistent\n",
    "        # samples from the generator over the course of training. This allows for visualizing\n",
    "        # the progression of generated images or comparing them across different training iterations.\n",
    "        self.sample_z = torch.rand((self.batch_size, self.z_dim))\n",
    "        if self.device == 'cuda:0':\n",
    "            self.sample_z = self.sample_z.cuda()\n",
    "        \n",
    "        print('---------------INITIALIZATION-----------------')\n",
    "        print('| Model: WGAN with Adam and Gradient Penalty |')\n",
    "        print('----------------------------------------------')\n",
    "\n",
    "\n",
    "    def train(self):    \n",
    "        self.y_real = torch.ones(self.batch_size, 1)\n",
    "        self.y_fake = torch.zeros(self.batch_size, 1)\n",
    "\n",
    "        if self.device == 'cuda:0':\n",
    "            self.y_real = self.y_real.cuda()\n",
    "            self.y_fake =  self.y_fake.cuda()\n",
    "\n",
    "        self.D.train() #Discriminator in train mode\n",
    "\n",
    "        print('Start training!')\n",
    "        tot_iter = 0\n",
    "        for epoch in range(self.epoch):\n",
    "            iteration_losses_G = []                                                  # Auxiliary arrays to compute the mean loss for each epoch\n",
    "            iteration_losses_D = []\n",
    "            \n",
    "            self.G.train()                                                           # Generator in train mode\n",
    "\n",
    "            for iter, (x_train, _) in enumerate(self.data_loader):\n",
    "                if iter == self.data_loader.dataset.__len__() // self.batch_size:    # Exit the loop when it has been used the whole dataset\n",
    "                    break\n",
    "\n",
    "                z_noise = torch.rand((self.batch_size, self.z_dim))\n",
    "                if self.device == 'cuda:0':\n",
    "                    x_train = x_train.cuda()\n",
    "                    z_noise = z_noise.cuda()\n",
    "\n",
    "                # PART 1: UPDATE THE DISCRIMINATOR\n",
    "                self.D_optimizer.zero_grad()\n",
    "\n",
    "                D_real = self.D(x_train)\n",
    "                D_real_loss = -torch.mean(D_real)\n",
    "\n",
    "                G_ = self.G(z_noise)\n",
    "                D_fake = self.D(G_)\n",
    "                D_fake_loss = torch.mean(D_fake)\n",
    "\n",
    "                # Gradient penalty\n",
    "                alpha = torch.rand((self.batch_size, 1, 1, 1))\n",
    "                if self.device == 'cuda:0':\n",
    "                    alpha = alpha.cuda()\n",
    "\n",
    "                x_hat = alpha * x_train.data + (1 - alpha) * G_.data\n",
    "                x_hat.requires_grad = True\n",
    "\n",
    "                pred_hat = self.D(x_hat)\n",
    "                if self.device == 'cuda:0':\n",
    "                    gradients = grad(outputs=pred_hat, inputs=x_hat, grad_outputs=torch.ones(pred_hat.size()).cuda(),\n",
    "                                 create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "                else:\n",
    "                    gradients = grad(outputs=pred_hat, inputs=x_hat, grad_outputs=torch.ones(pred_hat.size()),\n",
    "                                     create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "                gradient_penalty = self.lambda_ * ((gradients.view(gradients.size()[0], -1).norm(2, 1) - 1) ** 2).mean()\n",
    "\n",
    "                D_loss = D_real_loss + D_fake_loss + gradient_penalty # Loss with gradient penalty\n",
    "\n",
    "                D_loss.backward()\n",
    "                self.D_optimizer.step()\n",
    "\n",
    "                if ((iter+1) % self.iteration_g_per_d) == 0:\n",
    "                    # PART 2: UPDATE THE GENERATOR\n",
    "                    self.G_optimizer.zero_grad()\n",
    "\n",
    "                    G_ = self.G(z_noise)\n",
    "                    D_fake = self.D(G_)\n",
    "                    G_loss = -torch.mean(D_fake)\n",
    "\n",
    "                    iteration_losses_G.append(G_loss.item())\n",
    "\n",
    "                    G_loss.backward()\n",
    "                    self.G_optimizer.step()\n",
    "\n",
    "                    iteration_losses_D.append(D_loss.item())\n",
    "                \n",
    "                if tot_iter%1000 == 0:\n",
    "                    with torch.no_grad():\n",
    "                        score=self.IS()\n",
    "                        self.inception_scores.append(score[0].item())\n",
    "                        distance=self.FID()\n",
    "                        self.frechet_inception_distances.append(distance.item())\n",
    "                tot_iter += 1\n",
    "\n",
    "            self.G_losses.append(np.mean(iteration_losses_G))\n",
    "            self.D_losses.append(np.mean(iteration_losses_D))\n",
    "\n",
    "            print(f'Epoch: {epoch+1}/{self.epoch}')\n",
    "            print(f'Average Discriminator loss: {self.D_losses[-1]}')\n",
    "            print(f'Average Generator loss: {self.G_losses[-1]}\\n')\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                self.visualize_results((epoch+1))\n",
    "\n",
    "        print(\"Training finished!\")\n",
    "\n",
    "        #self.save()\n",
    "        generate_animation(self.result_dir + '/' + self.dataset + '/' + self.model_name + '/' + self.model_name,\n",
    "                                 self.epoch)\n",
    "        loss_plot(self.G_losses, self.D_losses, os.path.join(self.save_dir, self.dataset, self.model_name), self.model_name)\n",
    "        save_scores(self.inception_scores, self.save_dir, self.dataset, self.model_name, IS=True)\n",
    "        save_scores(self.frechet_inception_distances, self.save_dir, self.dataset, self.model_name, FID=True)\n",
    "        save_loss(self.G_losses, self.save_dir, self.dataset, self.model_name, Generator=True)\n",
    "        save_loss(self.D_losses, self.save_dir, self.dataset, self.model_name, Discriminator=True)\n",
    "    \n",
    "\n",
    "\n",
    "    def IS(self):\n",
    "        self.G.eval()\n",
    "        images = self.G(self.sample_z)\n",
    "        self.inception.update(images.cpu())\n",
    "        IS=self.inception.compute()   \n",
    "        return IS\n",
    "    \n",
    "\n",
    "\n",
    "    def FID(self):\n",
    "        self.G.eval()\n",
    "        imagesG = self.G(self.sample_z)\n",
    "        imagesR=self.data_loader.__iter__().__next__()[0]\n",
    "        self.f.update(imagesR.cpu(), real=True)\n",
    "        self.f.update(imagesG.cpu(), real=False)\n",
    "        FID=self.f.compute()\n",
    "        return FID\n",
    "\n",
    "\n",
    "\n",
    "    def visualize_results(self, epoch, fix=True):\n",
    "        '''\n",
    "        By calling this method during the training loop, you can visualize and save the \n",
    "        generated samples at regular intervals to monitor the progress \n",
    "        of the generator's output over the course of training.\n",
    "        '''\n",
    "        self.G.eval()                           # Set the generator in evaluation mode.\n",
    "\n",
    "        if not os.path.exists(self.result_dir + '/' + self.dataset + '/' + self.model_name):\n",
    "            os.makedirs(self.result_dir + '/' + self.dataset + '/' + self.model_name)\n",
    "\n",
    "        samples = self.G(self.sample_z)         # These samples represent the generator's output at the given epoch        \n",
    "        \n",
    "        # The dimensions are transposed to match the image format\n",
    "        if self.device == 'cuda:0':\n",
    "            samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n",
    "        else:\n",
    "            samples = samples.data.numpy().transpose(0, 2, 3, 1)\n",
    "        samples = (samples + 1) / 2             # Normalizes the samples by scaling their pixel \n",
    "                                                # values from the range [-1, 1] to the range [0, 1]\n",
    "        save_images(samples, [8, 8],\n",
    "                          self.result_dir + '/' + self.dataset + '/' + self.model_name + '/' + self.model_name + '_epoch%03d' % epoch + '.png')\n",
    "\n",
    "\n",
    "\n",
    "    def print_networks(self):\n",
    "        print('---------- Networks architecture -------------')\n",
    "        print(self.G)\n",
    "        print(self.D)\n",
    "        print('-----------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN_ACGD(object):\n",
    "    def __init__(self, epoch, batch_size, save_dir, result_dir, dataset, device, input_size, lrG, lrD):\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.dataset = dataset\n",
    "\n",
    "        self.save_dir = save_dir\n",
    "        self.result_dir = result_dir\n",
    "        \n",
    "        self.device = device\n",
    "\n",
    "        self.model_name = 'WGAN_ACGD'\n",
    "        self.z_dim = 62\n",
    "        self.lambda_ = 10\n",
    "        self.d_param_max = 0.01\n",
    "\n",
    "        \n",
    "        self.losses = []\n",
    "        self.inception_scores = []\n",
    "        self.frechet_inception_distances = []\n",
    "        \n",
    "        self.inception=InceptionScore(normalize=True)\n",
    "        self.f=FrechetInceptionDistance(feature=64,normalize=True)               \n",
    "        \n",
    "        # Transformation to be applied on data in the DataLoader function\n",
    "        transform = transforms.Compose([\n",
    "                                transforms.Resize((self.input_size, self.input_size)), \n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "                                ])\n",
    "\n",
    "        if self.dataset == 'cifar10':\n",
    "                self.data_loader = DataLoader(\n",
    "                    datasets.CIFAR10('data/cifar10', train=True, download=False, transform=transform),\n",
    "                    batch_size=batch_size, shuffle=True)\n",
    "        elif self.dataset == 'mnist':\n",
    "                self.data_loader = DataLoader(\n",
    "                    datasets.MNIST('data/mnist', train=True, download=False, transform=transform),\n",
    "                    batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        data = self.data_loader.__iter__().__next__()[0]\n",
    "\n",
    "        # Initialization of optimizers and of generator and discriminator\n",
    "        self.G = Generator(input_dim=self.z_dim, output_dim=data.shape[1], input_size=self.input_size)\n",
    "        self.D = Discriminator(input_dim=data.shape[1], output_dim=1, input_size=self.input_size)\n",
    "        self.optimizer = ACGD(max_params=self.G.parameters(), min_params=self.D.parameters(), lr_max=lrG, lr_min=lrD)\n",
    "        \n",
    "\n",
    "        if self.device == 'cuda:0':\n",
    "            self.G.cuda()\n",
    "            self.D.cuda()\n",
    "\n",
    "        # Fixed noise: By setting up a fixed noise vector, the WGAN can generate consistent\n",
    "        # samples from the generator over the course of training. This allows for visualizing\n",
    "        # the progression of generated images or comparing them across different training iterations.\n",
    "        self.sample_z = torch.rand((self.batch_size, self.z_dim))\n",
    "        if self.device == 'cuda:0':\n",
    "            self.sample_z = self.sample_z.cuda()\n",
    "\n",
    "        print('----------------------INITIALIZATION------------------------')\n",
    "        print('| Model: WGAN using Competitive Gradient Descent optimizer |')\n",
    "        print('------------------------------------------------------------')\n",
    "        \n",
    "\n",
    "    def train(self):\n",
    "        self.y_real = torch.ones(self.batch_size, 1)    # Initialize labels for real samples (i.e. 1)\n",
    "        self.y_fake = torch.zeros(self.batch_size, 1)   # Initialize labels for fake samples (i.e. 0)\n",
    "\n",
    "        if self.device == 'cuda:0':\n",
    "            self.y_real = self.y_real.cuda()\n",
    "            self.y_fake = self.y_fake.cuda()\n",
    "\n",
    "        self.D.train()                                  #D network in train mode\n",
    "\n",
    "        print('Start training!')\n",
    "        tot_iter = 0\n",
    "        for epoch in range(self.epoch):\n",
    "            self.G.train()                              # G network in train mode\n",
    "            iteration_losses = []                       # Auxilary array to compute the mean loss for each epoch\n",
    "            for iter, (x_train, _) in enumerate(self.data_loader):\n",
    "                if iter == self.data_loader.dataset.__len__() // self.batch_size:\n",
    "                    break\n",
    "\n",
    "                z_noise = torch.rand((self.batch_size, self.z_dim))\n",
    "\n",
    "                if self.device == 'cuda:0':\n",
    "                    x_train = x_train.cuda()\n",
    "                    z_noise = z_noise.cuda()\n",
    "\n",
    "                # UPDATE NETWORKS\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                D_real = self.D(x_train)                # Computes the discriminator output for real data\n",
    "                D_real_loss = -torch.mean(D_real)       # Calculates the loss for the discriminator on real data. \n",
    "                                                        # The objective is to maximize the average output of the discriminator for real data.\n",
    "\n",
    "                G_ = self.G(z_noise)                    # Generates fake data using the generator\n",
    "                D_fake = self.D(G_)                     # Computes the discriminator output for fake data.\n",
    "                D_fake_loss = torch.mean(D_fake)        # Calculates the loss for the discriminator on fake data. \n",
    "                                                        # The objective is to minimize the average output of the discriminator for fake data.\n",
    "\n",
    "                loss = D_real_loss + D_fake_loss        # Calculates the total discriminator loss as the sum of the losses on real and fake data.\n",
    "                \n",
    "                iteration_losses.append(loss.detach().cpu())\n",
    "                self.optimizer.step(loss=loss)\n",
    "\n",
    "                # Clipping D parameters to a specified range to enforce Lipschitz continuity.\n",
    "                for p in self.D.parameters():\n",
    "                    p.data.clamp_(-self.d_param_max, self.d_param_max)\n",
    "                \n",
    "                if tot_iter%1000 == 0:\n",
    "                    with torch.no_grad():\n",
    "                        score=self.IS()\n",
    "                        self.inception_scores.append(score[0].item())\n",
    "                        distance=self.FID()\n",
    "                        self.frechet_inception_distances.append(distance.item())\n",
    "                tot_iter += 1\n",
    "\n",
    "            self.losses.append(np.mean(iteration_losses))\n",
    "\n",
    "            print(f'Epoch: {epoch+1}/{self.epoch}')\n",
    "            print(f'Average loss: {self.losses[-1]}')\n",
    "\n",
    "            with torch.no_grad():\n",
    "                self.visualize_results((epoch+1))\n",
    "\n",
    "        print(\"Training finished.\")\n",
    "\n",
    "        generate_animation(self.result_dir + '/' + self.dataset + '/' + self.model_name + '/' + self.model_name,\n",
    "                                 self.epoch)\n",
    "        loss_plot_ACGD(self.losses, os.path.join(self.save_dir, self.dataset, self.model_name), self.model_name)\n",
    "        save_scores(self.inception_scores, self.save_dir, self.dataset, self.model_name, IS=True)\n",
    "        save_scores(self.frechet_inception_distances, self.save_dir, self.dataset, self.model_name, FID=True)\n",
    "        save_loss(self.losses, self.save_dir, self.dataset, self.model_name)\n",
    "\n",
    "\n",
    "    def visualize_results(self, epoch):\n",
    "        self.G.eval()\n",
    "\n",
    "        if not os.path.exists(self.result_dir + '/' + self.dataset + '/' + self.model_name):\n",
    "            os.makedirs(self.result_dir + '/' + self.dataset + '/' + self.model_name)\n",
    "\n",
    "        samples = self.G(self.sample_z)\n",
    "        if self.device == 'cuda:0':\n",
    "            samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n",
    "        else:\n",
    "            samples = samples.data.numpy().transpose(0, 2, 3, 1)\n",
    "\n",
    "        samples = (samples + 1) / 2\n",
    "        save_images(samples, [8, 8],\n",
    "                          self.result_dir + '/' + self.dataset + '/' + self.model_name + '/' + self.model_name + '_epoch%03d' % epoch + '.png')\n",
    "    \n",
    "\n",
    "\n",
    "    def IS(self):\n",
    "        self.G.eval()\n",
    "        images = self.G(self.sample_z)\n",
    "        self.inception.update(images.cpu())\n",
    "        IS=self.inception.compute()   \n",
    "        return IS\n",
    "\n",
    "\n",
    "\n",
    "    def FID(self):\n",
    "        self.G.eval()\n",
    "        imagesG = self.G(self.sample_z)\n",
    "        imagesR=self.data_loader.__iter__().__next__()[0]\n",
    "        self.f.update(imagesR.cpu(), real=True)\n",
    "        self.f.update(imagesG.cpu(), real=False)\n",
    "        FID=self.f.compute()\n",
    "        return FID\n",
    "    \n",
    "\n",
    "    def save_scores_loss(self):\n",
    "        save_scores\n",
    "\n",
    "\n",
    "    def print_networks(self):\n",
    "        print('---------- Networks architecture -------------')\n",
    "        print(self.G)\n",
    "        print(self.D)\n",
    "        print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dange\\anaconda3\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Metric `InceptionScore` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------INITIALIZATION------------------------\n",
      "| Model: WGAN using Competitve Gradient Descent optimizer. |\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# PARAMETERS\n",
    "\n",
    "# Define dataset ['cifar10', 'mnist']\n",
    "dataset = 'cifar10'\n",
    "\n",
    "# Define WGAN type [WGAN, WGAN_GP, WGAN_ACGD]\n",
    "gan_type = 'WGAN'\n",
    "\n",
    "# Define number of epoch\n",
    "epoch = 100\n",
    "\n",
    "# Define batch_size\n",
    "batch_size = 64\n",
    "\n",
    "# Define input_size\n",
    "input_size = 32\n",
    "\n",
    "# Define directory for saving results and models\n",
    "save_dir = 'models'\n",
    "result_dir = 'results'\n",
    "\n",
    "\n",
    "# Defining learning rates\n",
    "lrG = 0.0001        # Generator\n",
    "lrD = 0.0001        # Discriminator\n",
    "\n",
    "# Adam beta parameters\n",
    "beta1 = 0.5\n",
    "beta2 = 0.9\n",
    "\n",
    "# 'cuda' if GPU is available, 'cpu' else\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "if gan_type == 'WGAN':\n",
    "    wgan = WGAN(epoch, batch_size, save_dir, result_dir, dataset, device, input_size, lrG, lrD, beta1, beta2)\n",
    "elif gan_type == 'WGAN_GP':\n",
    "    wgan = WGAN_GP(epoch, batch_size, save_dir, result_dir, dataset, device, input_size, lrG, lrD, beta1, beta2)\n",
    "elif gan_type == 'WGAN_ACGD':\n",
    "    wgan = WGAN_ACGD(epoch, batch_size, save_dir, result_dir, dataset, device, input_size, lrG, lrD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training!\n",
      "Epoch: 1/1\n",
      "Average loss: -0.018492093309760094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "save_loss() got an unexpected keyword argument 'ACGD'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m wgan\u001b[39m.\u001b[39;49mtrain()\n",
      "Cell \u001b[1;32mIn[6], line 136\u001b[0m, in \u001b[0;36mWGAN_ACGD.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    134\u001b[0m save_scores(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minception_scores, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_dir, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name, IS\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    135\u001b[0m save_scores(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfrechet_inception_distances, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_dir, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name, FID\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 136\u001b[0m save_loss(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlosses, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_dir, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_name, ACGD\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: save_loss() got an unexpected keyword argument 'ACGD'"
     ]
    }
   ],
   "source": [
    "wgan.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
