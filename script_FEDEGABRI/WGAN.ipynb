{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing needed libraries\n",
    "\n",
    "import torch, time, os, pickle\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import grad\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from skimage.transform import resize\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=100, output_dim=1, input_size=32):\n",
    "        super(Generator, self).__init__()\n",
    "        self.input_dim = input_dim \n",
    "        self.output_dim = output_dim \n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 128 * (self.input_size // 4) * (self.input_size // 4)),\n",
    "            nn.BatchNorm1d(128 * (self.input_size // 4) * (self.input_size // 4)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # The following layers are used to upsample the input\n",
    "        #  noise and generate an output image. \n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, self.output_dim, 4, 2, 1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        # This function initializes the weights and biases of the \n",
    "        # generator's layers:\n",
    "        initialize_weights(self) \n",
    "\n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        The input to the forward method represents the input noise \n",
    "        to the generator model. It returns the generated output image.\n",
    "        '''\n",
    "        x = self.fc(input)\n",
    "        x = x.view(-1, 128, (self.input_size // 4), (self.input_size // 4)) # reshapes x to match the expected size for the subsequent transposed convolutional layers. \n",
    "        x = self.deconv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim=1, output_dim=1, input_size=32):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(self.input_dim, 64, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 * (self.input_size // 4) * (self.input_size // 4), 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, self.output_dim),\n",
    "            # nn.Sigmoid(),\n",
    "        )\n",
    "        # This function initializes the weights and biases of the \n",
    "        # discriminator's layers:\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        The input to the forward method represents the input image\n",
    "        It returns the output prediction, which represents the discriminator's assessment of the input image.\n",
    "        '''\n",
    "        x = self.conv(input)\n",
    "        x = x.view(-1, 128 * (self.input_size // 4) * (self.input_size // 4))\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN(object):\n",
    "    def __init__(self, epoch, batch_size, save_dir, result_dir, dataset, device, input_size, lrG, lrD, beta1, beta2):\n",
    "    \n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.save_dir = save_dir\n",
    "        self.result_dir = result_dir\n",
    "        self.device = device\n",
    "        self.dataset = dataset\n",
    "        self.input_size = input_size    # Default: 32\n",
    "\n",
    "        self.model_name = 'WGAN'        \n",
    "        self.z_dim = 62                 # s an integer that represents the dimensionality of the (Gaussian) random input vector used by the generator.\n",
    "        self.d_param_max = 0.01         # Clipping value\n",
    "        self.iteration_g_per_d = 5      # specifies the number of iterations of the generator per discriminator iteration. \n",
    "                                        # This controls the relative training frequency of the generator and discriminator.\n",
    "\n",
    "        # transformation to be applied on data in the DataLoader function\n",
    "        transform = transforms.Compose([\n",
    "                                        transforms.Resize((input_size, input_size)), \n",
    "                                        transforms.ToTensor(), \n",
    "                                        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "                                        ])\n",
    "        \n",
    "        if self.dataset == 'cifar10':\n",
    "                self.data_loader = DataLoader(\n",
    "                    datasets.CIFAR10('data/cifar10', train=True, download=False, transform=transform),\n",
    "                    batch_size=batch_size, shuffle=True)\n",
    "        elif self.dataset == 'mnist':\n",
    "                self.data_loader = DataLoader(\n",
    "                    datasets.MNIST('data/mnist', train=True, download=True, transform=transform),\n",
    "                    batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "\n",
    "        data = self.data_loader.__iter__().__next__()[0]\n",
    "\n",
    "        # Initialize generator, discriminator and optimizers\n",
    "        self.G = Generator(input_dim=self.z_dim, output_dim=data.shape[1], input_size=self.input_size)\n",
    "        self.D = Discriminator(input_dim=data.shape[1], output_dim=1, input_size=self.input_size)\n",
    "        self.G_optimizer = optim.Adam(self.G.parameters(), lr=lrG, betas=(beta1, beta2))\n",
    "        self.D_optimizer = optim.Adam(self.D.parameters(), lr=lrD, betas=(beta1, beta2))\n",
    "\n",
    "        if self.device == 'cuda':\n",
    "            self.G.cuda()\n",
    "            self.D.cuda()\n",
    "\n",
    "        # Fixed noise: By setting up a fixed noise vector, the WGAN can generate consistent\n",
    "        # samples from the generator over the course of training. This allows for visualizing\n",
    "        # the progression of generated images or comparing them across different training iterations.\n",
    "        self.sample_z = torch.rand((self.batch_size, self.z_dim))\n",
    "        if self.device == 'cuda':\n",
    "            self.sample_z = self.sample_z.cuda()\n",
    "\n",
    "    def train(self):\n",
    "        self.D_losses = []\n",
    "        self.G_losses = []\n",
    "        self.inception_scores = [] \n",
    "\n",
    "        self.y_real = torch.ones(self.batch_size, 1) # Initialize labels for real samples (i.e. 1)\n",
    "        self.y_fake = torch.zeros(self.batch_size, 1) # Initialize labels for fake samples (i.e. 0)\n",
    "\n",
    "        if self.device == 'cuda':\n",
    "            self.y_real = self.y_real.cuda()\n",
    "            self.y_fake = self.y_fake.cuda()\n",
    "\n",
    "        self.D.train() #D network in train mode\n",
    "\n",
    "        print('Start training!')\n",
    "\n",
    "        for epoch in range(self.epoch):\n",
    "            self.G.train() #G network in train mode\n",
    "\n",
    "            for iter, (x_train, _) in enumerate(self.data_loader):\n",
    "                if iter == self.data_loader.dataset.__len__() // self.batch_size:\n",
    "                    break\n",
    "\n",
    "                z_noise = torch.rand((self.batch_size, self.z_dim))\n",
    "\n",
    "                if self.device == 'cuda':\n",
    "                    x_train = x_train.cuda()\n",
    "                    z_noise = z_noise.cuda()\n",
    "\n",
    "                # PART 1: UPDATE THE DISCRIMINATOR\n",
    "                self.D_optimizer.zero_grad()\n",
    "\n",
    "                D_real = self.D(x_train) # Computes the discriminator output for real data\n",
    "                D_real_loss = -torch.mean(D_real) # Calculates the loss for the discriminator on real data. \n",
    "                                                  # The objective is to maximize the average output of the discriminator for real data.\n",
    "\n",
    "                G_ = self.G(z_noise) # Generates fake data using the generator\n",
    "                D_fake = self.D(G_) # Computes the discriminator output for fake data.\n",
    "                D_fake_loss = torch.mean(D_fake) # Calculates the loss for the discriminator on fake data. \n",
    "                                                 # The objective is to minimize the average output of the discriminator for fake data.\n",
    "\n",
    "                D_loss = D_real_loss + D_fake_loss # Calculates the total discriminator loss as the sum of the losses on real and fake data.\n",
    "\n",
    "                D_loss.backward()\n",
    "                self.D_optimizer.step()\n",
    "\n",
    "                # Clipping D parameters to a specified range to enforce Lipschitz continuity.\n",
    "                for p in self.D.parameters():\n",
    "                    p.data.clamp_(-self.d_param_max, self.d_param_max)\n",
    "\n",
    "                if ((iter+1) % self.iteration_g_per_d) == 0:\n",
    "                    # PART 2: UPDATE THE GENERATOR\n",
    "                    self.G_optimizer.zero_grad()\n",
    "\n",
    "                    G_ = self.G(z_noise)\n",
    "                    D_fake = self.D(G_)\n",
    "                    G_loss = -torch.mean(D_fake) # Calculates the generator loss as the negative average output of the discriminator for fake data. \n",
    "                                                 # The objective is to maximize the average output of the discriminator for the generated fake data.\n",
    "\n",
    "                    self.G_losses.append(G_loss.item())\n",
    "\n",
    "                    G_loss.backward()\n",
    "\n",
    "                    self.G_optimizer.step()\n",
    "\n",
    "                    self.D_losses.append(D_loss.item())\n",
    "                \n",
    "                #if (iter % 100) == 0:\n",
    "                #   self.inception_scores.append(self.calculateInceptionScore())\n",
    "\n",
    "            print(f'Epoch: {epoch}/{self.epoch}')\n",
    "            print(f'Average Discriminator loss: {np.mean(self.D_losses)}')\n",
    "            print(f'Average Generator loss: {np.mean(self.G_losses)}\\n')\n",
    "\n",
    "            with torch.no_grad():\n",
    "                self.visualize_results((epoch+1))\n",
    "\n",
    "        print(\"Training finished.\")\n",
    "\n",
    "        #self.save()\n",
    "        generate_animation(self.result_dir + '/' + self.dataset + '/' + self.model_name + '/' + self.model_name,\n",
    "                                 self.epoch)\n",
    "        loss_plot(self.G_losses, self.D_losses, os.path.join(self.save_dir, self.dataset, self.model_name), self.model_name)\n",
    "        # is_plot(self.inception_scores)\n",
    "    \n",
    "    def calculateInceptionScore(self):\n",
    "        self.G.eval()\n",
    "        \n",
    "        samples = self.G(self.sample_z)\n",
    "        \n",
    "        eps=1E-16\n",
    "        scores=[]\n",
    "        samples=samples.cpu().data.numpy()\n",
    "        samples=scale_images(samples, (299,299,3))\n",
    "        samples=preprocess_input(samples)\n",
    "        model=InceptionV3()\n",
    "        p_yx=model.predict(samples)\n",
    "        p_y = np.expand_dims(p_yx.mean(axis=0), 0)\n",
    "        kl_d = p_yx * (np.log(p_yx + eps) - np.log(p_y + eps))\n",
    "        sum_kl_d = kl_d.sum(axis=1)\n",
    "        avg_kl_d = np.mean(sum_kl_d)\n",
    "        is_score = np.exp(avg_kl_d)\n",
    "        scores.append(is_score)\n",
    "        return scores\n",
    "        \n",
    "\n",
    "    def visualize_results(self, epoch):\n",
    "        self.G.eval()\n",
    "\n",
    "        if not os.path.exists(self.result_dir + '/' + self.dataset + '/' + self.model_name):\n",
    "            os.makedirs(self.result_dir + '/' + self.dataset + '/' + self.model_name)\n",
    "\n",
    "        samples = self.G(self.sample_z)\n",
    "        \n",
    "        if self.device == 'cuda':\n",
    "            samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n",
    "        else:\n",
    "            samples = samples.data.numpy().transpose(0, 2, 3, 1)\n",
    "\n",
    "\n",
    "        samples = (samples + 1) / 2\n",
    "        save_images(samples, [8, 8],\n",
    "                          self.result_dir + '/' + self.dataset + '/' + self.model_name + '/' + self.model_name + '_epoch%03d' % epoch + '.png')\n",
    "    \n",
    "    def print_networks(self):\n",
    "        print('---------- Networks architecture -------------')\n",
    "        print(self.G)\n",
    "        print(self.D)\n",
    "        print('-----------------------------------------------')\n",
    "\n",
    "\n",
    "    '''\n",
    "    def save(self):\n",
    "        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n",
    "\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "        torch.save(self.G.state_dict(), os.path.join(save_dir, self.model_name + '_G.pkl'))\n",
    "        torch.save(self.D.state_dict(), os.path.join(save_dir, self.model_name + '_D.pkl'))\n",
    "\n",
    "        with open(os.path.join(save_dir, self.model_name + '_history.pkl'), 'wb') as f:\n",
    "            pickle.dump(self.train_hist, f)\n",
    "\n",
    "    def load(self):\n",
    "        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n",
    "\n",
    "        self.G.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + '_G.pkl')))\n",
    "        self.D.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + '_D.pkl')))\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN_GP(object):\n",
    "    def __init__(self, epoch, batch_size, save_dir, result_dir, dataset, device, input_size, lrG, lrD, beta1, beta2):\n",
    "        # parameters\n",
    "        self.epoch = epoch\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.save_dir = save_dir\n",
    "        self.result_dir = result_dir\n",
    "        self.device = device\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.model_name = 'WGAN_GP'\n",
    "        self.z_dim = 62\n",
    "        self.lambda_ = 10\n",
    "        self.iteration_g_per_d = 5               \n",
    "        \n",
    "        # transformation to be applied on data in the DataLoader function\n",
    "        transform = transforms.Compose([\n",
    "                                transforms.Resize((self.input_size, self.input_size)), \n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "                                ])\n",
    "\n",
    "        if self.dataset == 'cifar10':\n",
    "                self.data_loader = DataLoader(\n",
    "                    datasets.CIFAR10('data/cifar10', train=True, download=False, transform=transform),\n",
    "                    batch_size=batch_size, shuffle=True)\n",
    "        elif self.dataset == 'mnist':\n",
    "                self.data_loader = DataLoader(\n",
    "                    datasets.MNIST('data/mnist', train=True, download=True, transform=transform),\n",
    "                    batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        data = self.data_loader.__iter__().__next__()[0]\n",
    "\n",
    "        # Initialization of optimizers and of generator and discriminator\n",
    "        self.G = Generator(input_dim=self.z_dim, output_dim=data.shape[1], input_size=self.input_size)\n",
    "        self.D = Discriminator(input_dim=data.shape[1], output_dim=1, input_size=self.input_size)\n",
    "        self.G_optimizer = optim.Adam(self.G.parameters(), lr=lrG, betas=(beta1, beta2))\n",
    "        self.D_optimizer = optim.Adam(self.D.parameters(), lr=lrD, betas=(beta1, beta2))\n",
    "\n",
    "        if self.device == 'cuda':\n",
    "            self.G.cuda()\n",
    "            self.D.cuda()\n",
    "\n",
    "        # Fixed noise: By setting up a fixed noise vector, the WGAN can generate consistent\n",
    "        # samples from the generator over the course of training. This allows for visualizing\n",
    "        # the progression of generated images or comparing them across different training iterations.\n",
    "        self.sample_z = torch.rand((self.batch_size, self.z_dim))\n",
    "        if self.device == 'cuda':\n",
    "            self.sample_z = self.sample_z.cuda()\n",
    "\n",
    "    def train(self):\n",
    "        self.G_losses = []\n",
    "        self.D_losses = []\n",
    "\n",
    "        self.y_real = torch.ones(self.batch_size, 1)\n",
    "        self.y_fake = torch.zeros(self.batch_size, 1)\n",
    "\n",
    "        if self.device == 'cuda':\n",
    "            self.y_real = self.y_real.cuda()\n",
    "            self.y_fake =  self.y_fake.cuda()\n",
    "\n",
    "        self.D.train() #Discriminator in train mode\n",
    "        print('Start training!')\n",
    "\n",
    "        for epoch in range(self.epoch):\n",
    "            self.G.train() #Generator in train mode\n",
    "\n",
    "            for iter, (x_train, _) in enumerate(self.data_loader):\n",
    "                if iter == self.data_loader.dataset.__len__() // self.batch_size:\n",
    "                    break\n",
    "\n",
    "                z_noise = torch.rand((self.batch_size, self.z_dim))\n",
    "                if self.device == 'cuda':\n",
    "                    x_train = x_train.cuda()\n",
    "                    z_noise = z_noise.cuda()\n",
    "\n",
    "                # PART 1: UPDATE THE DISCRIMINATOR\n",
    "                self.D_optimizer.zero_grad()\n",
    "\n",
    "                D_real = self.D(x_train)\n",
    "                D_real_loss = -torch.mean(D_real)\n",
    "\n",
    "                G_ = self.G(z_noise)\n",
    "                D_fake = self.D(G_)\n",
    "                D_fake_loss = torch.mean(D_fake)\n",
    "\n",
    "                # Gradient penalty\n",
    "                alpha = torch.rand((self.batch_size, 1, 1, 1))\n",
    "                if self.device == 'cuda':\n",
    "                    alpha = alpha.cuda()\n",
    "\n",
    "                x_hat = alpha * x_train.data + (1 - alpha) * G_.data\n",
    "                x_hat.requires_grad = True\n",
    "\n",
    "                pred_hat = self.D(x_hat)\n",
    "                if self.device == 'cuda':\n",
    "                    gradients = grad(outputs=pred_hat, inputs=x_hat, grad_outputs=torch.ones(pred_hat.size()).cuda(),\n",
    "                                 create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "                else:\n",
    "                    gradients = grad(outputs=pred_hat, inputs=x_hat, grad_outputs=torch.ones(pred_hat.size()),\n",
    "                                     create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "                gradient_penalty = self.lambda_ * ((gradients.view(gradients.size()[0], -1).norm(2, 1) - 1) ** 2).mean()\n",
    "\n",
    "                D_loss = D_real_loss + D_fake_loss + gradient_penalty #loss with gradient penalty\n",
    "\n",
    "                D_loss.backward()\n",
    "                self.D_optimizer.step()\n",
    "\n",
    "                if ((iter+1) % self.iteration_g_per_d) == 0:\n",
    "                    # PART 2: UPDATE THE GENERATOR\n",
    "                    self.G_optimizer.zero_grad()\n",
    "\n",
    "                    G_ = self.G(z_noise)\n",
    "                    D_fake = self.D(G_)\n",
    "                    G_loss = -torch.mean(D_fake)\n",
    "                    self.G_losses.append(G_loss.item())\n",
    "\n",
    "                    G_loss.backward()\n",
    "                    self.G_optimizer.step()\n",
    "\n",
    "                    self.D_losses.append(D_loss.item())\n",
    "                \n",
    "            print(f'Epoch: {epoch+1}/{self.epoch}')\n",
    "            print(f'Average Discriminator loss: {np.mean(self.D_losses)}')\n",
    "            print(f'Average Generator loss: {np.mean(self.G_losses)}\\n')\n",
    "\n",
    "            with torch.no_grad():\n",
    "                self.visualize_results((epoch+1))\n",
    "\n",
    "        print(\"Training finished!\")\n",
    "\n",
    "        #self.save()\n",
    "        generate_animation(self.result_dir + '/' + self.dataset + '/' + self.model_name + '/' + self.model_name,\n",
    "                                 self.epoch)\n",
    "        loss_plot(self.G_losses, self.D_losses, os.path.join(self.save_dir, self.dataset, self.model_name), self.model_name)\n",
    "    \n",
    "    def calculateInceptionScore(self):\n",
    "        '''\n",
    "        Calculates the Inception Score for the generated samples produced by the generator.\n",
    "        The Inception Score is a metric used to evaluate the quality and diversity of generated images. \n",
    "        It measures how well the generated images resemble real images and how diverse the generated images are in terms of class distributions. \n",
    "        A higher Inception Score indicates better quality and diversity of generated images.\n",
    "        '''\n",
    "        self.G.eval()\n",
    "\n",
    "        samples = self.G(self.sample_z)\n",
    "        \n",
    "        eps=1E-16\n",
    "        scores=[]\n",
    "        samples=samples.cpu().data.numpy()\n",
    "        samples=scale_images(samples, (299,299,3))\n",
    "        samples=preprocess_input(samples)\n",
    "        model=InceptionV3()\n",
    "        p_yx=model.predict(samples)\n",
    "        p_y = np.expand_dims(p_yx.mean(axis=0), 0)\n",
    "        kl_d = p_yx * (np.log(p_yx + eps) - np.log(p_y + eps))\n",
    "        sum_kl_d = kl_d.sum(axis=1)\n",
    "        avg_kl_d = np.mean(sum_kl_d)\n",
    "        is_score = np.exp(avg_kl_d)\n",
    "        scores.append(is_score)\n",
    "        return scores\n",
    "        \n",
    "    def visualize_results(self, epoch, fix=True):\n",
    "\n",
    "        '''\n",
    "        By calling this method during the training loop, you can visualize and save the \n",
    "        generated samples at regular intervals to monitor the progress \n",
    "        of the generator's output over the course of training.\n",
    "        '''\n",
    "\n",
    "        self.G.eval() # set the generator in evaluation mode.\n",
    "\n",
    "        if not os.path.exists(self.result_dir + '/' + self.dataset + '/' + self.model_name):\n",
    "            os.makedirs(self.result_dir + '/' + self.dataset + '/' + self.model_name)\n",
    "\n",
    "        samples = self.G(self.sample_z) # These samples represent the generator's output at the given epoch\n",
    "        \n",
    "        # The dimensions are transposed to match the image format\n",
    "        if self.device == 'cuda':\n",
    "            samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n",
    "        else:\n",
    "            samples = samples.data.numpy().transpose(0, 2, 3, 1)\n",
    "\n",
    "        samples = (samples + 1) / 2 # Normalizes the samples by scaling their pixel values from the range [-1, 1] to the range [0, 1]\n",
    "        save_images(samples, [8, 8],\n",
    "                          self.result_dir + '/' + self.dataset + '/' + self.model_name + '/' + self.model_name + '_epoch%03d' % epoch + '.png')\n",
    "\n",
    "    def print_networks(self):\n",
    "        print('---------- Networks architecture -------------')\n",
    "        print(self.G)\n",
    "        print(self.D)\n",
    "        print('-----------------------------------------------')\n",
    "\n",
    "    '''\n",
    "    def save(self):\n",
    "        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n",
    "\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "        torch.save(self.G.state_dict(), os.path.join(save_dir, self.model_name + '_G.pkl'))\n",
    "        torch.save(self.D.state_dict(), os.path.join(save_dir, self.model_name + '_D.pkl'))\n",
    "\n",
    "        with open(os.path.join(save_dir, self.model_name + '_history.pkl'), 'wb') as f:\n",
    "            pickle.dump(self.train_hist, f)\n",
    "\n",
    "    def load(self):\n",
    "        save_dir = os.path.join(self.save_dir, self.dataset, self.model_name)\n",
    "\n",
    "        self.G.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + '_G.pkl')))\n",
    "        self.D.load_state_dict(torch.load(os.path.join(save_dir, self.model_name + '_D.pkl')))\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nif gan_type == 'WGAN':\\n    wgan = WGAN(epoch, batch_size, save_dir, result_dir, dataset, device, input_size, lrG, lrD, beta1, beta2)\\nelif gan_type == 'WGAN_GP':\\n    wgan = WGAN_GP(epoch, batch_size, save_dir, result_dir, dataset, device, input_size, lrG, lrD, beta1, beta2)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PARAMETERS\n",
    "\n",
    "# Define dataset\n",
    "dataset = 'cifar10'\n",
    "\n",
    "# Define WGAN type (WGAN or WGAN_GP)\n",
    "gan_type = 'WGAN_GP'\n",
    "\n",
    "# Define number of epoch\n",
    "epoch = 100\n",
    "\n",
    "# Define batch_size\n",
    "batch_size = 64\n",
    "\n",
    "# Define input_size\n",
    "input_size = 32\n",
    "\n",
    "# Define directory for saving results and models\n",
    "save_dir = 'models'\n",
    "result_dir = 'results'\n",
    "\n",
    "# Defining learning rates\n",
    "lrG = 0.0002        # Generator\n",
    "lrD = 0.0002        # Discriminator\n",
    "\n",
    "# Adam beta parameters\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "\n",
    "# 'cuda' if GPU is available, 'cpu' else\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "wgan = WGAN(epoch, batch_size, save_dir, result_dir, dataset, device, input_size, lrG, lrD, beta1, beta2)\n",
    "wgan_gp = WGAN_GP(epoch, batch_size, save_dir, result_dir, dataset, device, input_size, lrG, lrD, beta1, beta2)\n",
    "\n",
    "\n",
    "'''\n",
    "if gan_type == 'WGAN':\n",
    "    wgan = WGAN(epoch, batch_size, save_dir, result_dir, dataset, device, input_size, lrG, lrD, beta1, beta2)\n",
    "elif gan_type == 'WGAN_GP':\n",
    "    wgan = WGAN_GP(epoch, batch_size, save_dir, result_dir, dataset, device, input_size, lrG, lrD, beta1, beta2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training!\n",
      "Epoch: 0/100\n",
      "Average Discriminator loss: -0.015227458327829551\n",
      "Average Generator loss: 0.00446021875074784\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m wgan\u001b[39m.\u001b[39;49mtrain()\n",
      "Cell \u001b[1;32mIn[4], line 117\u001b[0m, in \u001b[0;36mWGAN.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mG_losses\u001b[39m.\u001b[39mappend(G_loss\u001b[39m.\u001b[39mitem())\n\u001b[0;32m    115\u001b[0m     G_loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m--> 117\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mG_optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m    119\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mD_losses\u001b[39m.\u001b[39mappend(D_loss\u001b[39m.\u001b[39mitem())\n\u001b[0;32m    121\u001b[0m \u001b[39m#if (iter % 100) == 0:\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[39m#   self.inception_scores.append(self.calculateInceptionScore())\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    130\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[0;32m    133\u001b[0m         group,\n\u001b[0;32m    134\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    139\u001b[0m         state_steps)\n\u001b[1;32m--> 141\u001b[0m     adam(\n\u001b[0;32m    142\u001b[0m         params_with_grad,\n\u001b[0;32m    143\u001b[0m         grads,\n\u001b[0;32m    144\u001b[0m         exp_avgs,\n\u001b[0;32m    145\u001b[0m         exp_avg_sqs,\n\u001b[0;32m    146\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    147\u001b[0m         state_steps,\n\u001b[0;32m    148\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    149\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    150\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    151\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    152\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    153\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    154\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    155\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    156\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    157\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    158\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    159\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    160\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 281\u001b[0m func(params,\n\u001b[0;32m    282\u001b[0m      grads,\n\u001b[0;32m    283\u001b[0m      exp_avgs,\n\u001b[0;32m    284\u001b[0m      exp_avg_sqs,\n\u001b[0;32m    285\u001b[0m      max_exp_avg_sqs,\n\u001b[0;32m    286\u001b[0m      state_steps,\n\u001b[0;32m    287\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[0;32m    288\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    289\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    290\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[0;32m    291\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[0;32m    292\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[0;32m    293\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[0;32m    294\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[0;32m    295\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[0;32m    296\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[0;32m    297\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\adam.py:345\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[39m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m    344\u001b[0m exp_avg\u001b[39m.\u001b[39mmul_(beta1)\u001b[39m.\u001b[39madd_(grad, alpha\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta1)\n\u001b[1;32m--> 345\u001b[0m exp_avg_sq\u001b[39m.\u001b[39mmul_(beta2)\u001b[39m.\u001b[39maddcmul_(grad, grad\u001b[39m.\u001b[39;49mconj(), value\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta2)\n\u001b[0;32m    347\u001b[0m \u001b[39mif\u001b[39;00m capturable \u001b[39mor\u001b[39;00m differentiable:\n\u001b[0;32m    348\u001b[0m     step \u001b[39m=\u001b[39m step_t\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wgan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m wgan_gp\u001b[39m.\u001b[39;49mtrain()\n",
      "Cell \u001b[1;32mIn[5], line 116\u001b[0m, in \u001b[0;36mWGAN_GP.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mG_optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m    115\u001b[0m G_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mG(z_noise)\n\u001b[1;32m--> 116\u001b[0m D_fake \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mD(G_)\n\u001b[0;32m    117\u001b[0m G_loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mtorch\u001b[39m.\u001b[39mmean(D_fake)\n\u001b[0;32m    118\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mG_losses\u001b[39m.\u001b[39mappend(G_loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[3], line 31\u001b[0m, in \u001b[0;36mDiscriminator.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m     27\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[39m    The input to the forward method represents the input image\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[39m    It returns the output prediction, which represents the discriminator's assessment of the input image.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m     32\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m128\u001b[39m \u001b[39m*\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m4\u001b[39m) \u001b[39m*\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m4\u001b[39m))\n\u001b[0;32m     33\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\activation.py:777\u001b[0m, in \u001b[0;36mLeakyReLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    776\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 777\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mleaky_relu(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnegative_slope, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\functional.py:1632\u001b[0m, in \u001b[0;36mleaky_relu\u001b[1;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[0;32m   1630\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39mleaky_relu_(\u001b[39minput\u001b[39m, negative_slope)\n\u001b[0;32m   1631\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1632\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mleaky_relu(\u001b[39minput\u001b[39;49m, negative_slope)\n\u001b[0;32m   1633\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wgan_gp.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
